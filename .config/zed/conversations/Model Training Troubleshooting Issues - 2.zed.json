{"id":"7561533f-80aa-4890-a71d-336880e6e9a5","zed":"context","version":"0.4.0","text":"\n\n\n\n```py aigs/simple_autoencoder/train.py:1-205\n# Excerpt from: \n\"\"\"Training and evaluation logic.\"\"\"\nimport matplotlib.pyplot as plt\nfrom flax import linen as nn\nimport models\nfrom logger import log\nimport jax\nfrom jax import random\nimport jax.numpy as jnp\nimport optax\nimport numpy as np\nfrom tqdm import tqdm\nfrom nsd_data import get_train_test_datasets, get_batches, get_train_test_mnist, get_train_test_cifar100\nfrom visualisations import plot_losses, plot_original_reconstruction\nfrom flax.training import train_state\nfrom typing import Any\n\nclass TrainState(train_state.TrainState):\n    batch_stats: Any\n\ndef create_train_state(key, init_data, latent_dim, fmri_voxels, learning_rate):\n    \"\"\"Creates initial `TrainState`.\"\"\"\n    model_cls = models.model(latent_dim, fmri_voxels)\n    variables = model_cls.init(\n        {'params': key, 'dropout': key},\n        init_data,\n        dropout_rng=key,\n        training=True\n    )\n    return TrainState.create(\n        apply_fn=model_cls.apply,\n        params=variables['params'],\n        batch_stats=variables['batch_stats'],\n        tx=optax.adamw(learning_rate)\n    )\n\ndef compute_metrics(recon_x, x, latent_vec):\n    mse_loss = jnp.mean(jnp.square(recon_x - x))\n    return {'loss': mse_loss }\n\ndef train_step(state, batch, key, latent_dim, l1_coefficient=0.01):\n    key, dropout_rng = jax.random.split(key)\n    \"\"\"Performs a single training step updating model parameters based on batch data.\n\n    Args:\n        state: TrainState object containing model state and optimizer\n        batch: Current batch of training data\n        key: Random key for generating latent vectors\n        latent_dim: Dimension of the latent space\n        l1_coefficient: Optional coefficient for L1 regularization (default 0.01)\n\n    Returns:\n        Tuple containing updated state and training loss for the batch\n    \"\"\"\n    def loss_fn(params):\n        fmri_voxels = batch.shape[1]\n        variables = {'params': params, 'batch_stats': state.batch_stats}\n        (recon_x, latent_vec), new_model_state = models.model(latent_dim, fmri_voxels).apply(\n            variables, batch, dropout_rng, training=True, mutable=['batch_stats'], rngs={'dropout': dropout_rng}\n        )\n        mse_loss = jnp.mean(jnp.square(recon_x - batch))\n        # l2_loss = jnp.sum(jnp.square(latent_vec))\n        # sparsity_loss = l1_coefficient * jnp.sum(latent_vec) # jnp.sum(jnp.abs(latent_vec))\n\n        return mse_loss, new_model_state\n\n    (loss, new_model_state), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n    state = state.apply_gradients(grads=grads)\n    state = state.replace(batch_stats=new_model_state['batch_stats'])\n    return state, loss\n\n\ndef evaluate_fun(state, loader, key, config, validation_step, num_steps=2):\n    key, dropout_rng = jax.random.split(key)\n    \"\"\"Evaluation function that computes metrics on batches.\n       Evaluates 2 batches by default (during training),\n       while evaluating the entire dataset during testing.\n\n    Args:\n        params: Model parameters to evaluate\n        train_loader: Generator yielding training batches\n        key: Random key for generating latent vectors\n        latent_dim: Dimension of the latent space\n        num_steps: Number of evaluation steps to perform\n\n    Returns:\n        List of tuples containing (metrics, data, latent vectors) for each evaluation step\n        Average of the losses\n    \"\"\"\n    def eval_model(batch):\n        variables = {'params': state.params, 'batch_stats': state.batch_stats}\n        reconstruction, latent_vecs = models.model(config.latent_dim, batch.shape[1]).apply(\n            variables, batch, dropout_rng=dropout_rng, training=False, mutable=False)\n        metrics = compute_metrics(reconstruction, batch, latent_vecs)\n        return metrics, (batch, reconstruction), latent_vecs\n\n    evaluations = []\n    for j in range(num_steps):\n        batch = loader[validation_step:validation_step+config.batch_size, :]\n        # fmri_voxels = batch.shape[1]\n        eval = eval_model(batch)\n        evaluations.append(eval)\n    return evaluations\n\ndef train_and_evaluate(config):\n    \"\"\"Train and evaulate pipeline.\"\"\"\n    rng = random.key(0)\n    rng, init_key = random.split(rng)\n\n    log('Initializing dataset...', 'TRAIN')\n    if config.ds == 'fmri':\n        train_ds, test_ds = get_train_test_datasets(subject=3, roi_class='floc-bodies', hem='lh')\n    elif config.ds == 'mnist':\n        train_ds, validation_ds = get_train_test_mnist()\n    else:\n        train_ds, validation_ds = get_train_test_cifar100()\n\n    print(f\"training ds shape: {train_ds.shape}\")\n    print(f\"test ds shape: {validation_ds.shape}\")\n    key1, key2 = random.split(rng)\n    train_loader = get_batches(train_ds, key1, config.batch_size)\n    validation_loader = get_batches(validation_ds, key2, config.batch_size)\n\n    train_size = train_ds.shape[0]\n    fmri_voxels = train_ds.shape[1]\n\n    # print(train_ds.min(), train_ds.max())\n\n    log('Initializing model...', 'TRAIN')\n    # va bene che siano uni o random gaussian noise?\n    init_data = jnp.ones((config.batch_size, fmri_voxels), jnp.float32)\n\n    log('Initializing state...', 'TRAIN')\n    state = create_train_state(init_key, init_data, config.latent_dim, fmri_voxels, config.learning_rate)\n\n    log(f'Calculating training steps per epochs (train_size: {train_size})...', 'TRAIN')\n    steps_per_epoch = train_size // int(config.batch_size)\n    if train_size % int(config.batch_size) != 0:\n        steps_per_epoch += 1\n    log(f\"{steps_per_epoch} steps for each ({config.num_epochs}) epoch\", 'TRAIN')\n\n\n    log('\\nstarting training', 'TRAIN')\n    train_losses = []\n    eval_losses = []\n\n    print(\"Train data stats:\", train_ds.min(), train_ds.max(), train_ds.mean())\n    print(\"Validation data stats:\", validation_ds.min(), validation_ds.max(), validation_ds.mean())\n\n    for epoch in range(config.num_epochs):\n        # log(f'Epoch {epoch + 1}/{config.num_epochs}', 'TRAIN LOOP')\n        rng, epoch_key = jax.random.split(rng)\n        validation_step = 0\n\n        # Training loop\n        for step in (pbar := tqdm(range(0, len(train_loader), config.batch_size), total=steps_per_epoch)):\n            if step >= steps_per_epoch:\n                break\n\n            batch = train_ds[step:step+config.batch_size, :]\n            state, loss = train_step(state, batch, epoch_key, config.latent_dim)\n\n            # save the loss every 5% of steps\n            if step % (steps_per_epoch // 50) == 0:\n                # add training loss\n                train_losses.append(loss)\n\n                rng, key = jax.random.split(rng)\n                evaluations = evaluate_fun(\n                    state, validation_loader, epoch_key, config, validation_step, num_steps=1\n                )\n                validation_step += config.batch_size\n\n                # add validation losses\n                eval_tmp_losses = [eval[0]['loss'] for eval in evaluations]\n                eval_losses.extend(eval_tmp_losses)\n\n                # only plotting the first evaluation\n                metrics, (evaluated_batches, reconstructions), latent_vecs = evaluations[0]\n                del evaluations\n\n                # once every epoch, plot the original and reconstructed images\n                if step % (steps_per_epoch // 1) == 0:\n                    plot_original_reconstruction(evaluated_batches, reconstructions, config.ds, epoch, step)\n\n            pbar.set_description(f\"epoch {epoch} loss: {str(loss)[:5]}\")\n\n        key1, key2 = random.split(rng)\n        train_loader = get_batches(train_ds, key1, config.batch_size)\n        validation_loader = get_batches(validation_ds, key2, config.batch_size)\n\n    plot_losses(train_losses, eval_losses, steps_per_epoch)\n\n    # plot the latent space\n    # final_variables = {'params': state.params, 'batch_stats': state.batch_stats}\n    # dropout_rng, key = random.split(rng)\n    # latent_vectors = []\n    # categories = []\n    # for step, batch in enumerate(validation_loader):\n    #     _, latent_vec= models.model(config.latent_dim, batch.shape[1]).apply(\n    #                 final_variables, batch, dropout_rng=dropout_rng, training=False, mutable=False)\n    #     latent_vectors.append(latent_vec)\n    #     categories.append(step)\n    #     del latent_vec\n    # plot_latent_space(latent_vectors, categories)\n\n```\nwhy is my training not working?\nLooking at your training code, there are a few potential issues that could be affecting your training:\n\n1. **Data Normalization**: I notice you're printing data stats, but it's not clear if your data is properly normalized. Neural networks typically work better with normalized data (mean 0, standard deviation 1 or values between 0-1). Consider adding:\n\n```python\n# Add normalization before training\ntrain_ds = (train_ds - train_ds.mean()) / train_ds.std()\nvalidation_ds = (validation_ds - validation_ds.mean()) / validation_ds.std()\n```\n\n2. **Learning Rate**: Your learning rate might not be appropriate. Make sure config.learning_rate is set to a reasonable value (try starting with 1e-3 or 1e-4):\n\n```python\nconfig.learning_rate = 1e-3  # Adjust this value\n```\n\n3. **Batch Statistics**: Your model seems to use batch normalization (since you're tracking batch_stats), but you might need to ensure proper handling of training vs evaluation modes.\n\n4. **Loss Function**: Your loss function is currently only using MSE loss. Depending on your data, you might want to add regularization:\n\n```python\ndef loss_fn(params):\n    # ... existing code ...\n    mse_loss = jnp.mean(jnp.square(recon_x - batch))\n    l2_reg = 0.001 * sum(jnp.sum(jnp.square(p)) for p in jax.tree_leaves(params))\n    return mse_loss + l2_reg, new_model_state\n```\n\n5. **Gradient Clipping**: Consider adding gradient clipping to prevent exploding gradients:\n\n```python\ntx = optax.chain(\n    optax.clip(1.0),  # Add gradient clipping\n    optax.adamw(learning_rate)\n)\n```\n\n6. **Model Architecture**: The issue might be in your model architecture (models.py). Make sure:\n   - The model capacity is appropriate for your data\n   - The activation functions are suitable\n   - The layer sizes transition appropriately\n\nTo debug:\n1. Add more detailed logging:\n```python\nprint(f\"Batch stats: min={batch.min()}, max={batch.max()}, mean={batch.mean()}\")\nprint(f\"Reconstruction stats: min={recon_x.min()}, max={recon_x.max()}, mean={recon_x.mean()}\")\n```\n\n2. Monitor gradients:\n```python\ngrad_norm = jnp.sqrt(sum(jnp.sum(jnp.square(g)) for g in jax.tree_leaves(grads)))\nprint(f\"Gradient norm: {grad_norm}\")\n```\n\n3. Check if loss is actually decreasing during training by plotting more frequently.\n\nCould you share:\n1. What specific behavior are you seeing that indicates training isn't working?\n2. What does your loss curve look like?\n3. Can you share your models.py file?\n\nThis would help provide more specific guidance.\n","messages":[{"id":{"replica_id":0,"value":0},"start":0,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":68}}},{"id":{"replica_id":0,"value":10},"start":8338,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":66}}},{"id":{"replica_id":0,"value":11},"start":10815,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":67}}}],"summary":"Model Training Troubleshooting Issues","slash_command_output_sections":[{"range":{"start":0,"end":1},"icon":"Library","label":"Default","metadata":null}]}