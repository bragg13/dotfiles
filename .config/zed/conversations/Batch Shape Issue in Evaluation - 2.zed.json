{"id":"a7ef6576-6249-4263-89ab-f7821c9cb6cb","zed":"context","version":"0.4.0","text":"\n\n\n\n```py aigs/simple_autoencoder/train.py:1-223\n# Excerpt from: \n\"\"\"Training and evaluation logic.\"\"\"\nimport matplotlib.pyplot as plt\nfrom flax import linen as nn\nfrom flax import nnx\nimport models\nfrom logger import log\nimport jax\nfrom jax import random\nimport jax.numpy as jnp\nimport optax\nimport numpy as np\nfrom tqdm import tqdm\nfrom nsd_data import get_train_test_datasets, get_batches, get_train_test_mnist, get_train_test_cifar10\nfrom visualisations import plot_losses, plot_original_reconstruction\nfrom flax.training import train_state\nfrom typing import Any\n\nclass TrainState(train_state.TrainState):\n    batch_stats: Any\n\ndef create_train_state(key, init_data, latent_dim, fmri_voxels, learning_rate):\n    \"\"\"Creates initial `TrainState`.\"\"\"\n    model_cls = models.model(latent_dim, fmri_voxels)\n    variables = model_cls.init(\n        {'params': key, 'dropout': key},\n        init_data,\n        dropout_rng=key,\n        training=True\n    )\n    return TrainState.create(\n        apply_fn=model_cls.apply,\n        params=variables['params'],\n        batch_stats=variables['batch_stats'],\n        tx=optax.adamw(learning_rate)\n    )\n\ndef compute_metrics(recon_x, x, latent_vec ):\n    mse_loss = jnp.mean(jnp.square(recon_x - x))\n    return {'loss': mse_loss }\n\ndef train_step(state, batch, key, latent_dim, l1_coefficient=0.01):\n    key, dropout_rng = jax.random.split(key)\n    \"\"\"Performs a single training step updating model parameters based on batch data.\n\n    Args:\n        state: TrainState object containing model state and optimizer\n        batch: Current batch of training data\n        key: Random key for generating latent vectors\n        latent_dim: Dimension of the latent space\n        l1_coefficient: Optional coefficient for L1 regularization (default 0.01)\n\n    Returns:\n        Tuple containing updated state and training loss for the batch\n    \"\"\"\n    def loss_fn(params):\n\n        fmri_voxels = batch.shape[1]\n        variables = {'params': params, 'batch_stats': state.batch_stats}\n        (recon_x, latent_vec), new_model_state = models.model(latent_dim, fmri_voxels).apply(\n            variables, batch, dropout_rng, training=True, mutable=['batch_stats'], rngs={'dropout': dropout_rng}\n        )\n        mse_loss = jnp.mean(jnp.square(recon_x - batch))\n\n        # sparsity_loss = l1_coefficient * jnp.sum(latent_vec) # jnp.sum(jnp.abs(latent_vec))\n        return mse_loss , new_model_state\n\n    (loss, new_model_state), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n    state = state.apply_gradients(grads=grads)\n    state = state.replace(batch_stats=new_model_state['batch_stats'])\n    return state, loss\n\n\ndef evaluate_fun(state, loader, key, config, validation_step):\n    key, dropout_rng = jax.random.split(key)\n    \"\"\"Evaluation function that computes metrics on batches.\n       Evaluates 1 batch by default (during training),\n       while evaluating the entire dataset during testing.\n\n    Args:\n        params: Model parameters to evaluate\n        train_loader: Generator yielding training batches\n        key: Random key for generating latent vectors\n        latent_dim: Dimension of the latent space\n        num_steps: Number of evaluation steps to perform\n\n    Returns:\n        List of tuples containing (metrics, data, latent vectors) for each evaluation step\n        Average of the losses\n    \"\"\"\n    def eval_model(batch):\n        variables = {'params': state.params, 'batch_stats': state.batch_stats}\n        reconstruction, latent_vecs = models.model(config.latent_dim, batch.shape[1]).apply(\n            variables, batch, dropout_rng=dropout_rng, training=False, mutable=False)\n        metrics = compute_metrics(reconstruction, batch, latent_vecs )\n        return metrics, (batch, reconstruction), latent_vecs\n\n    print(validation_step)\n    batch = loader[validation_step:validation_step+config.batch_size]\n    print(batch.shape)\n    eval = eval_model(batch)\n    print(eval)\n    return eval\n    # evaluations = []\n    # for j in range(num_steps):\n    #     batch = loader[validation_step:validation_step+config.batch_size, :]\n    #     # fmri_voxels = batch.shape[1]\n    #     eval = eval_model(batch )\n    #     evaluations.append(eval)\n    # return evaluations\n\ndef train_and_evaluate(config):\n    \"\"\"Train and evaulate pipeline.\"\"\"\n    rng = random.key(0)\n    rng, init_key = random.split(rng)\n\n    log('Initializing dataset...', 'TRAIN')\n    rate_reconstruction_printing = 1\n    if config.ds == 'fmri':\n        train_ds, validation_ds = get_train_test_datasets(subject=3, roi_class=config.roi_class, hem=config.hem)\n    elif config.ds == 'mnist':\n        train_ds, validation_ds = get_train_test_mnist()\n    else:\n        train_ds, validation_ds = get_train_test_cifar10()\n\n    print(f\"training ds shape: {train_ds.shape}\")\n    print(f\"test ds shape: {validation_ds.shape}\")\n    key1, key2 = random.split(rng)\n    train_loader = get_batches(train_ds, key1, config.batch_size)\n    validation_loader = get_batches(validation_ds, key2, config.batch_size)\n\n    train_size = train_ds.shape[0]\n    fmri_voxels = train_ds.shape[1]\n\n    # print(train_ds.min(), train_ds.max())\n\n    log('Initializing model...', 'TRAIN')\n    # va bene che siano uni o random gaussian noise?\n    init_data = jnp.ones((config.batch_size, fmri_voxels), jnp.float32)\n\n    log('Initializing state...', 'TRAIN')\n    state = create_train_state(init_key, init_data, config.latent_dim, fmri_voxels, config.learning_rate)\n\n    log(f'Calculating training steps per epochs (train_size: {train_size})...', 'TRAIN')\n    steps_per_epoch = train_size // int(config.batch_size)\n    if train_size % int(config.batch_size) != 0:\n        steps_per_epoch += 1\n    log(f\"{steps_per_epoch} steps for each ({config.num_epochs}) epoch\", 'TRAIN')\n\n\n    log('\\nstarting training', 'TRAIN')\n    train_losses = []\n    eval_losses = []\n\n    print(\"Train data stats:\", train_ds.min(), train_ds.max(), train_ds.mean())\n    print(\"Validation data stats:\", validation_ds.min(), validation_ds.max(), validation_ds.mean())\n\n    validation_step = 0\n    for epoch in range(config.num_epochs):\n        # log(f'Epoch {epoch + 1}/{config.num_epochs}', 'TRAIN LOOP')\n        rng, epoch_key = jax.random.split(rng)\n\n        # Training loop\n        for step in (pbar := tqdm(range(0, len(train_loader), config.batch_size), total=steps_per_epoch)):\n            # if step >= steps_per_epoch:\n            #     break\n\n            batch = train_ds[step:step+config.batch_size]\n            state, loss = train_step(state, batch, epoch_key, config.latent_dim)\n\n            if step % (steps_per_epoch // 5) == 0:\n                # add training loss\n                train_losses.append(loss)\n\n                rng, key = jax.random.split(rng)\n                # evaluations = evaluate_fun(\n                #     state, validation_loader, epoch_key, config, validation_step, num_steps=1\n                # )\n                metrics, (evaluated_batches, reconstructions), latent_vecs = evaluate_fun(state, validation_loader, epoch_key, config, validation_step)\n                validation_step += config.batch_size\n                eval_losses.append(metrics['loss'])\n\n                # add validation losses\n                # eval_tmp_losses = evaluations[0]['loss']\n                # eval_losses.append(eval_tmp_losses)\n\n                # only plotting the first evaluation\n                # metrics, (evaluated_batches, reconstructions), latent_vecs = evaluations[0]\n                # del evaluations\n\n            pbar.set_description(f\"epoch {epoch} loss: {str(loss)[:5]}\")\n\n        # once every 10 epochs, plot the original and reconstructed images of the last batch\n        if epoch % rate_reconstruction_printing == 0:\n            # batch_index = 0\n            # evaluations = evaluate_fun(\n            #     state, validation_loader, epoch_key, config, batch_index, num_steps=1\n            # )\n            # metrics, (evaluated_batches, reconstructions), latent_vecs = evaluations[0]\n            # del evaluations\n            metrics, (evaluated_batches, reconstructions), latent_vecs = evaluate_fun(state, validation_loader, epoch_key, config, validation_step)\n            validation_step += config.batch_size\n            eval_losses.append(metrics['loss'])\n            plot_original_reconstruction(evaluated_batches, reconstructions, config.ds, epoch)\n\n        key1, key2 = random.split(rng)\n        train_loader = get_batches(train_ds, key1, config.batch_size)\n        validation_loader = get_batches(validation_ds, key2, config.batch_size)\n\n    plot_losses(train_losses, eval_losses, steps_per_epoch)\n\n    # plot the latent space\n    # final_variables = {'params': state.params, 'batch_stats': state.batch_stats}\n    # dropout_rng, key = random.split(rng)\n    # latent_vectors = []\n    # categories = []\n    # for step, batch in enumerate(validation_loader):\n    #     _, latent_vec= models.model(config.latent_dim, batch.shape[1]).apply(\n    #                 final_variables, batch, dropout_rng=dropout_rng, training=False, mutable=False)\n    #     latent_vectors.append(latent_vec)\n    #     categories.append(step)\n    #     del latent_vec\n    # plot_latent_space(latent_vectors, categories)\n\n```\nwhat is wrong with my code, why am i getting some batch of shape (0, 3633) in evaluatio\n\n\n\n\n```py aigs/simple_autoencoder/train.py:1-223\n# Excerpt from: \n\"\"\"Training and evaluation logic.\"\"\"\nimport matplotlib.pyplot as plt\nfrom flax import linen as nn\nfrom flax import nnx\nimport models\nfrom logger import log\nimport jax\nfrom jax import random\nimport jax.numpy as jnp\nimport optax\nimport numpy as np\nfrom tqdm import tqdm\nfrom nsd_data import get_train_test_datasets, get_batches, get_train_test_mnist, get_train_test_cifar10\nfrom visualisations import plot_losses, plot_original_reconstruction\nfrom flax.training import train_state\nfrom typing import Any\n\nclass TrainState(train_state.TrainState):\n    batch_stats: Any\n\ndef create_train_state(key, init_data, latent_dim, fmri_voxels, learning_rate):\n    \"\"\"Creates initial `TrainState`.\"\"\"\n    model_cls = models.model(latent_dim, fmri_voxels)\n    variables = model_cls.init(\n        {'params': key, 'dropout': key},\n        init_data,\n        dropout_rng=key,\n        training=True\n    )\n    return TrainState.create(\n        apply_fn=model_cls.apply,\n        params=variables['params'],\n        batch_stats=variables['batch_stats'],\n        tx=optax.adamw(learning_rate)\n    )\n\ndef compute_metrics(recon_x, x, latent_vec ):\n    mse_loss = jnp.mean(jnp.square(recon_x - x))\n    return {'loss': mse_loss }\n\ndef train_step(state, batch, key, latent_dim, l1_coefficient=0.01):\n    key, dropout_rng = jax.random.split(key)\n    \"\"\"Performs a single training step updating model parameters based on batch data.\n\n    Args:\n        state: TrainState object containing model state and optimizer\n        batch: Current batch of training data\n        key: Random key for generating latent vectors\n        latent_dim: Dimension of the latent space\n        l1_coefficient: Optional coefficient for L1 regularization (default 0.01)\n\n    Returns:\n        Tuple containing updated state and training loss for the batch\n    \"\"\"\n    def loss_fn(params):\n\n        fmri_voxels = batch.shape[1]\n        variables = {'params': params, 'batch_stats': state.batch_stats}\n        (recon_x, latent_vec), new_model_state = models.model(latent_dim, fmri_voxels).apply(\n            variables, batch, dropout_rng, training=True, mutable=['batch_stats'], rngs={'dropout': dropout_rng}\n        )\n        mse_loss = jnp.mean(jnp.square(recon_x - batch))\n\n        # sparsity_loss = l1_coefficient * jnp.sum(latent_vec) # jnp.sum(jnp.abs(latent_vec))\n        return mse_loss , new_model_state\n\n    (loss, new_model_state), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n    state = state.apply_gradients(grads=grads)\n    state = state.replace(batch_stats=new_model_state['batch_stats'])\n    return state, loss\n\n\ndef evaluate_fun(state, loader, key, config, validation_step):\n    key, dropout_rng = jax.random.split(key)\n    \"\"\"Evaluation function that computes metrics on batches.\n       Evaluates 1 batch by default (during training),\n       while evaluating the entire dataset during testing.\n\n    Args:\n        params: Model parameters to evaluate\n        train_loader: Generator yielding training batches\n        key: Random key for generating latent vectors\n        latent_dim: Dimension of the latent space\n        num_steps: Number of evaluation steps to perform\n\n    Returns:\n        List of tuples containing (metrics, data, latent vectors) for each evaluation step\n        Average of the losses\n    \"\"\"\n    def eval_model(batch):\n        variables = {'params': state.params, 'batch_stats': state.batch_stats}\n        reconstruction, latent_vecs = models.model(config.latent_dim, batch.shape[1]).apply(\n            variables, batch, dropout_rng=dropout_rng, training=False, mutable=False)\n        metrics = compute_metrics(reconstruction, batch, latent_vecs )\n        return metrics, (batch, reconstruction), latent_vecs\n\n    print(validation_step)\n    batch = loader[validation_step:validation_step+config.batch_size]\n    print(batch.shape)\n    eval = eval_model(batch)\n    print(eval)\n    return eval\n    # evaluations = []\n    # for j in range(num_steps):\n    #     batch = loader[validation_step:validation_step+config.batch_size, :]\n    #     # fmri_voxels = batch.shape[1]\n    #     eval = eval_model(batch )\n    #     evaluations.append(eval)\n    # return evaluations\n\ndef train_and_evaluate(config):\n    \"\"\"Train and evaulate pipeline.\"\"\"\n    rng = random.key(0)\n    rng, init_key = random.split(rng)\n\n    log('Initializing dataset...', 'TRAIN')\n    rate_reconstruction_printing = 1\n    if config.ds == 'fmri':\n        train_ds, validation_ds = get_train_test_datasets(subject=3, roi_class=config.roi_class, hem=config.hem)\n    elif config.ds == 'mnist':\n        train_ds, validation_ds = get_train_test_mnist()\n    else:\n        train_ds, validation_ds = get_train_test_cifar10()\n\n    print(f\"training ds shape: {train_ds.shape}\")\n    print(f\"test ds shape: {validation_ds.shape}\")\n    key1, key2 = random.split(rng)\n    train_loader = get_batches(train_ds, key1, config.batch_size)\n    validation_loader = get_batches(validation_ds, key2, config.batch_size)\n\n    train_size = train_ds.shape[0]\n    fmri_voxels = train_ds.shape[1]\n\n    # print(train_ds.min(), train_ds.max())\n\n    log('Initializing model...', 'TRAIN')\n    # va bene che siano uni o random gaussian noise?\n    init_data = jnp.ones((config.batch_size, fmri_voxels), jnp.float32)\n\n    log('Initializing state...', 'TRAIN')\n    state = create_train_state(init_key, init_data, config.latent_dim, fmri_voxels, config.learning_rate)\n\n    log(f'Calculating training steps per epochs (train_size: {train_size})...', 'TRAIN')\n    steps_per_epoch = train_size // int(config.batch_size)\n    if train_size % int(config.batch_size) != 0:\n        steps_per_epoch += 1\n    log(f\"{steps_per_epoch} steps for each ({config.num_epochs}) epoch\", 'TRAIN')\n\n\n    log('\\nstarting training', 'TRAIN')\n    train_losses = []\n    eval_losses = []\n\n    print(\"Train data stats:\", train_ds.min(), train_ds.max(), train_ds.mean())\n    print(\"Validation data stats:\", validation_ds.min(), validation_ds.max(), validation_ds.mean())\n\n    validation_step = 0\n    for epoch in range(config.num_epochs):\n        # log(f'Epoch {epoch + 1}/{config.num_epochs}', 'TRAIN LOOP')\n        rng, epoch_key = jax.random.split(rng)\n\n        # Training loop\n        for step in (pbar := tqdm(range(0, len(train_loader), config.batch_size), total=steps_per_epoch)):\n            # if step >= steps_per_epoch:\n            #     break\n\n            batch = train_ds[step:step+config.batch_size]\n            state, loss = train_step(state, batch, epoch_key, config.latent_dim)\n\n            if step % (steps_per_epoch // 5) == 0:\n                # add training loss\n                train_losses.append(loss)\n\n                rng, key = jax.random.split(rng)\n                # evaluations = evaluate_fun(\n                #     state, validation_loader, epoch_key, config, validation_step, num_steps=1\n                # )\n                metrics, (evaluated_batches, reconstructions), latent_vecs = evaluate_fun(state, validation_loader, epoch_key, config, validation_step)\n                validation_step += config.batch_size\n                eval_losses.append(metrics['loss'])\n\n                # add validation losses\n                # eval_tmp_losses = evaluations[0]['loss']\n                # eval_losses.append(eval_tmp_losses)\n\n                # only plotting the first evaluation\n                # metrics, (evaluated_batches, reconstructions), latent_vecs = evaluations[0]\n                # del evaluations\n\n            pbar.set_description(f\"epoch {epoch} loss: {str(loss)[:5]}\")\n\n        # once every 10 epochs, plot the original and reconstructed images of the last batch\n        if epoch % rate_reconstruction_printing == 0:\n            # batch_index = 0\n            # evaluations = evaluate_fun(\n            #     state, validation_loader, epoch_key, config, batch_index, num_steps=1\n            # )\n            # metrics, (evaluated_batches, reconstructions), latent_vecs = evaluations[0]\n            # del evaluations\n            metrics, (evaluated_batches, reconstructions), latent_vecs = evaluate_fun(state, validation_loader, epoch_key, config, validation_step)\n            validation_step += config.batch_size\n            eval_losses.append(metrics['loss'])\n            plot_original_reconstruction(evaluated_batches, reconstructions, config.ds, epoch)\n\n        key1, key2 = random.split(rng)\n        train_loader = get_batches(train_ds, key1, config.batch_size)\n        validation_loader = get_batches(validation_ds, key2, config.batch_size)\n\n    plot_losses(train_losses, eval_losses, steps_per_epoch)\n\n    # plot the latent space\n    # final_variables = {'params': state.params, 'batch_stats': state.batch_stats}\n    # dropout_rng, key = random.split(rng)\n    # latent_vectors = []\n    # categories = []\n    # for step, batch in enumerate(validation_loader):\n    #     _, latent_vec= models.model(config.latent_dim, batch.shape[1]).apply(\n    #                 final_variables, batch, dropout_rng=dropout_rng, training=False, mutable=False)\n    #     latent_vectors.append(latent_vec)\n    #     categories.append(step)\n    #     del latent_vec\n    # plot_latent_space(latent_vectors, categories)\n\n```\nwhat is wrong with my code, why am i getting some batch of shape (0, 3633) in evaluation\nThe issue you're encountering, where you get a batch of shape `(0, 3633)` during evaluation, is likely due to how you're slicing the validation dataset. Specifically, the `validation_step` variable is being incremented without checking if it exceeds the size of the validation dataset. This can result in an empty slice, which produces a batch with zero samples.\n\nTo fix this, you should add a check to ensure that `validation_step` does not exceed the size of the validation dataset. Here's how you can modify your code:\n\n1. Add a check to ensure `validation_step` does not exceed the size of the validation dataset.\n2. Reset `validation_step` if it exceeds the dataset size.\n\nHere's the modified code:\n\n```python\ndef evaluate_fun(state, loader, key, config, validation_step):\n    key, dropout_rng = jax.random.split(key)\n    \"\"\"Evaluation function that computes metrics on batches.\n       Evaluates 1 batch by default (during training),\n       while evaluating the entire dataset during testing.\n\n    Args:\n        params: Model parameters to evaluate\n        train_loader: Generator yielding training batches\n        key: Random key for generating latent vectors\n        latent_dim: Dimension of the latent space\n        num_steps: Number of evaluation steps to perform\n\n    Returns:\n        List of tuples containing (metrics, data, latent vectors) for each evaluation step\n        Average of the losses\n    \"\"\"\n    def eval_model(batch):\n        variables = {'params': state.params, 'batch_stats': state.batch_stats}\n        reconstruction, latent_vecs = models.model(config.latent_dim, batch.shape[1]).apply(\n            variables, batch, dropout_rng=dropout_rng, training=False, mutable=False)\n        metrics = compute_metrics(reconstruction, batch, latent_vecs )\n        return metrics, (batch, reconstruction), latent_vecs\n\n    print(validation_step)\n    if validation_step >= len(loader):\n        validation_step = 0  # Reset to the beginning if we exceed the dataset size\n    batch = loader[validation_step:validation_step+config.batch_size]\n    print(batch.shape)\n    eval = eval_model(batch)\n    print(eval)\n    return eval\n\ndef train_and_evaluate(config):\n    \"\"\"Train and evaulate pipeline.\"\"\"\n    rng = random.key(0)\n    rng, init_key = random.split(rng)\n\n    log('Initializing dataset...', 'TRAIN')\n    rate_reconstruction_printing = 1\n    if config.ds == 'fmri':\n        train_ds, validation_ds = get_train_test_datasets(subject=3, roi_class=config.roi_class, hem=config.hem)\n    elif config.ds == 'mnist':\n        train_ds, validation_ds = get_train_test_mnist()\n    else:\n        train_ds, validation_ds = get_train_test_cifar10()\n\n    print(f\"training ds shape: {train_ds.shape}\")\n    print(f\"test ds shape: {validation_ds.shape}\")\n    key1, key2 = random.split(rng)\n    train_loader = get_batches(train_ds, key1, config.batch_size)\n    validation_loader = get_batches(validation_ds, key2, config.batch_size)\n\n    train_size = train_ds.shape[0]\n    fmri_voxels = train_ds.shape[1]\n\n    log('Initializing model...', 'TRAIN')\n    init_data = jnp.ones((config.batch_size, fmri_voxels), jnp.float32)\n\n    log('Initializing state...', 'TRAIN')\n    state = create_train_state(init_key, init_data, config.latent_dim, fmri_voxels, config.learning_rate)\n\n    log(f'Calculating training steps per epochs (train_size: {train_size})...', 'TRAIN')\n    steps_per_epoch = train_size // int(config.batch_size)\n    if train_size % int(config.batch_size) != 0:\n        steps_per_epoch += 1\n    log(f\"{steps_per_epoch} steps for each ({config.num_epochs}) epoch\", 'TRAIN')\n\n    log('\\nstarting training', 'TRAIN')\n    train_losses = []\n    eval_losses = []\n\n    print(\"Train data stats:\", train_ds.min(), train_ds.max(), train_ds.mean())\n    print(\"Validation data stats:\", validation_ds.min(), validation_ds.max(), validation_ds.mean())\n\n    validation_step = 0\n    for epoch in range(config.num_epochs):\n        rng, epoch_key = jax.random.split(rng)\n\n        # Training loop\n        for step in (pbar := tqdm(range(0, len(train_loader), config.batch_size), total=steps_per_epoch)):\n            batch = train_ds[step:step+config.batch_size]\n            state, loss = train_step(state, batch, epoch_key, config.latent_dim)\n\n            if step % (steps_per_epoch // 5) == 0:\n                train_losses.append(loss)\n\n                rng, key = jax.random.split(rng)\n                metrics, (evaluated_batches, reconstructions), latent_vecs = evaluate_fun(state, validation_loader, epoch_key, config, validation_step)\n                validation_step += config.batch_size\n                if validation_step >= len(validation_loader):\n                    validation_step = 0  # Reset to the beginning if we exceed the dataset size\n                eval_losses.append(metrics['loss'])\n\n            pbar.set_description(f\"epoch {epoch} loss: {str(loss)[:5]}\")\n\n        if epoch % rate_reconstruction_printing == 0:\n            metrics, (evaluated_batches, reconstructions), latent_vecs = evaluate_fun(state, validation_loader, epoch_key, config, validation_step)\n            validation_step += config.batch_size\n            if validation_step >= len(validation_loader):\n                validation_step = 0  # Reset to the beginning if we exceed the dataset size\n            eval_losses.append(metrics['loss'])\n            plot_original_reconstruction(evaluated_batches, reconstructions, config.ds, epoch)\n\n        key1, key2 = random.split(rng)\n        train_loader = get_batches(train_ds, key1, config.batch_size)\n        validation_loader = get_batches(validation_ds, key2, config.batch_size)\n\n    plot_losses(train_losses, eval_losses, steps_per_epoch)\n```\n\nThis modification ensures that `validation_step` is reset to 0 if it exceeds the size of the validation dataset, preventing the creation of empty batches.\n","messages":[{"id":{"replica_id":0,"value":0},"start":0,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":121}}},{"id":{"replica_id":0,"value":23},"start":9287,"metadata":{"role":"assistant","status":{"Error":"an error occurred while interacting with the Anthropic API: overloaded_error: Overloaded"},"timestamp":{"replica_id":0,"value":122}}},{"id":{"replica_id":0,"value":24},"start":9288,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":123}}},{"id":{"replica_id":0,"value":35},"start":9289,"metadata":{"role":"assistant","status":{"Error":"Empty prompts aren't allowed. Please provide a non-empty prompt."},"timestamp":{"replica_id":0,"value":124}}},{"id":{"replica_id":0,"value":36},"start":9290,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":125}}},{"id":{"replica_id":0,"value":63},"start":18575,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":126}}},{"id":{"replica_id":0,"value":64},"start":24391,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":127}}}],"summary":"Batch Shape Issue in Evaluation","slash_command_output_sections":[{"range":{"start":0,"end":1},"icon":"Library","label":"Default","metadata":null}]}