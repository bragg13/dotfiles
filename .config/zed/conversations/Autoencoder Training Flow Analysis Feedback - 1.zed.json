{"id":"c5ce39bb-b9ef-44e9-8826-3c4f82ea7c75","zed":"context","version":"0.4.0","text":"\n```py aigs/simple_autoencoder/train.py:1-196\n# Excerpt from: \n\"\"\"Training and evaluation logic.\"\"\"\nimport matplotlib.pyplot as plt\nfrom flax import linen as nn\nimport models\nfrom logger import log\nimport jax\nfrom jax import random\nimport jax.numpy as jnp\nimport optax\nfrom tqdm import tqdm\nfrom nsd_data import get_train_test_datasets, get_batches\nfrom visualisations import plot_losses\nfrom flax.training import train_state\n\ndef compute_metrics(recon_x, x):\n    loss = jnp.mean(jnp.square(recon_x - x))\n    return {'loss': loss }\n\ndef train_step(state, batch, key, latent_dim, l1_coefficient=0.01):\n    \"\"\"Performs a single training step updating model parameters based on batch data.\n\n    Args:\n        state: TrainState object containing model state and optimizer\n        batch: Current batch of training data\n        key: Random key for generating latent vectors\n        latent_dim: Dimension of the latent space\n        l1_coefficient: Optional coefficient for L1 regularization (default 0.01)\n\n    Returns:\n        Tuple containing updated state and training loss for the batch\n    \"\"\"\n    def loss_fn(params, key):\n        fmri_voxels = batch.shape[1]\n        recon_x, latent_vec = models.model(latent_dim, fmri_voxels).apply(\n            {'params': params}, batch, training=True\n        )\n        mse_loss = jnp.mean(jnp.square(recon_x - batch))\n        # sparsity_loss = l1_coefficient * jnp.sum(latent_vec) # jnp.sum(jnp.abs(latent_vec))\n\n        return mse_loss\n\n    loss, grads = jax.value_and_grad(loss_fn)(state.params, key)\n    return state.apply_gradients(grads=grads), loss\n\ndef evaluate_fun(params, loader, key, latent_dim, num_steps=2):\n    \"\"\"Evaluation function that computes metrics on batches.\n       Evaluates 2 batches by default (during training),\n       while evaluating the entire dataset during testing.\n\n    Args:\n        params: Model parameters to evaluate\n        train_loader: Generator yielding training batches\n        key: Random key for generating latent vectors\n        latent_dim: Dimension of the latent space\n        num_steps: Number of evaluation steps to perform\n\n    Returns:\n        List of tuples containing (metrics, data, latent vectors) for each evaluation step\n        Average of the losses\n    \"\"\"\n    def eval_model(ae, training: bool):\n        reconstruction, latent_vecs = ae(batch, key)\n        metrics = compute_metrics(reconstruction, batch)\n        return metrics, (batch, reconstruction), latent_vecs\n\n    evaluations = []\n    for _ in range(num_steps):\n        batch = next(loader)\n        fmri_voxels = batch.shape[1]\n        eval = nn.apply(eval_model, models.model(latent_dim, fmri_voxels))({'params': params})\n        evaluations.append(eval)\n    return evaluations\n\ndef train_and_evaluate(config):\n    \"\"\"Train and evaulate pipeline.\"\"\"\n    rng = random.key(0)\n    rng, key = random.split(rng)\n\n    log('Initializing dataset...', 'TRAIN')\n    train_ds, test_ds = get_train_test_datasets(subject=3, roi_class='floc-bodies', hem='lh')\n    print(f\"training ds shape: {train_ds.shape}\")\n    print(f\"test ds shape: {test_ds.shape}\")\n    train_loader = get_batches(train_ds, config.batch_size)\n    test_loader = get_batches(test_ds, config.batch_size)\n    train_size = train_ds.shape[0]\n    test_size = test_ds.shape[0]\n    fmri_voxels = train_ds.shape[1]\n\n\n    log('Initializing model...', 'TRAIN')\n    # va bene che siano uni o random gaussian noise?\n    init_data = jnp.ones((config.batch_size, fmri_voxels), jnp.float32)  # fmri of 4 shown-images, 2000 voxels each\n\n    log('Initializing params...', 'TRAIN')\n    params = models.model(config.latent_dim, fmri_voxels).init(rng, init_data, training=True)['params']\n\n    log('Initializing state...', 'TRAIN')\n    state = train_state.TrainState.create(\n        apply_fn=models.model(config.latent_dim, fmri_voxels).apply,\n        params=params,\n        tx=optax.adamw(config.learning_rate),\n    )\n\n    rng, z_key, eval_rng = random.split(rng, 3)\n\n    log(f'Calculating training steps per epochs (train_size: {train_size})...', 'TRAIN')\n    steps_per_epoch = train_size // int(config.batch_size)\n    if train_size % int(config.batch_size) != 0:\n        steps_per_epoch += 1\n    log(f\"{steps_per_epoch} steps for each ({config.num_epochs}) epoch\", 'TRAIN')\n\n\n    log('\\nstarting training', 'TRAIN')\n    train_losses = []\n    eval_losses = []\n    test_losses = []\n\n    for epoch in range(config.num_epochs):\n        # log(f'Epoch {epoch + 1}/{config.num_epochs}', 'TRAIN LOOP')\n        rng, epoch_key = jax.random.split(rng)\n        epoch_train_losses = []\n        epoch_eval_losses = []\n\n        # Training loop\n        for step, batch in (pbar := tqdm(enumerate(train_loader), total=steps_per_epoch)):\n            if step >= steps_per_epoch:\n                break\n\n            state, loss = train_step(state, batch, epoch_key, config.latent_dim)\n            epoch_train_losses.append(loss)\n\n            # every 25% of steps for this epoch, evaluate the model\n            if step % (steps_per_epoch // 4) == 0:\n                rng, key = jax.random.split(rng)\n                evaluations = evaluate_fun(\n                    state.params, train_loader, key, config.latent_dim, num_steps=5\n                )\n\n                # calculate average loss among evaluations\n                eval_loss = sum([eval[0]['loss'] for eval in evaluations]) / len(evaluations)\n                epoch_eval_losses.append(eval_loss)\n\n                # only plotting the first evaluation\n                metrics, (evaluated_batches, reconstructions), latent_vecs = evaluations[0]\n                fig,axs = plt.subplots(5, 3, figsize=(15,15))\n                fig.suptitle('Validation set', fontsize=14)\n                axs[0, 0].set_title('original')\n                axs[0, 1].set_title('reconstructed')\n                axs[0, 2].set_title('difference')\n\n                # plot the first 5 samples of the first batch evaluated\n                for i in range(5):\n                    original = evaluated_batches[i][:3600].reshape(36, 100)\n                    reconstruction = reconstructions[i][:3600].reshape(36, 100)\n                    axs[i, 0].imshow(original, cmap='gray')\n                    axs[i, 1].imshow(reconstruction, cmap='gray')\n                    axs[i, 2].imshow(original - reconstruction, cmap='gray')\n\n                # should I append the eval loss to the training losses?\n                # train_losses.append(metrics['loss'])\n                fig.savefig(f'./results/epoch_{epoch}_step_{step}.png')\n                plt.close(fig)\n                del fig\n\n            pbar.set_description(f\"step {step} loss: {str(loss)[:5]}\")\n        train_losses.append(sum(epoch_train_losses)/len(epoch_train_losses))\n        eval_losses.append(sum(epoch_eval_losses)/len(epoch_eval_losses))\n\n\n\n    # evaluate on the test set\n    rng, key = jax.random.split(rng)\n    evaluations = evaluate_fun(\n        state.params, test_loader, key, config.latent_dim, num_steps=test_size // config.batch_size\n    )\n    metrics, (evaluated_batches, reconstructions), latent_vecs = evaluations[0]\n    test_losses = [eval[0]['loss'] for eval in evaluations]\n\n    # plotting only the first 5 samples of the first batch evaluated\n    fig, axs = plt.subplots(5, 3, figsize=(15,15))\n    fig.suptitle('Testing set', fontsize=14)\n    axs[0, 0].set_title('original')\n    axs[0, 1].set_title('reconstructed')\n    axs[0, 2].set_title('difference')\n    for i in range(5):\n        original = evaluated_batches[i][:3600].reshape(36, 100)\n        reconstruction = reconstructions[i][:3600].reshape(36, 100)\n        axs[i, 0].imshow(original, cmap='gray')\n        axs[i, 1].imshow(reconstruction, cmap='gray')\n        axs[i, 2].imshow(original - reconstruction, cmap='gray')\n\n    fig.savefig('./results/testing.png')\n    plt.close()\n\n    plot_losses(train_losses, eval_losses, test_losses)\n\n```\nI get error flax.errors.ScopeCollectionNotFound: Tried to access \"mean\" from collection \"batch_stats\" in \"/encoder/BatchNorm_0\" but the collection is empty. (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeCollectionNotFound)\nThis error typically occurs when using BatchNorm layers in Flax and not properly handling the batch statistics during training and inference. The issue is that your code needs to:\n\n1. Track and update batch statistics during training\n2. Use the collected statistics during evaluation/inference\n3. Properly pass and handle the mutable collections\n\nHere's how you can modify your code to fix this:\n\n1. First, modify the `train_step` function to handle mutable collections:\n\n```python\ndef train_step(state, batch, key, latent_dim, l1_coefficient=0.01):\n    def loss_fn(params):\n        fmri_voxels = batch.shape[1]\n        variables = {'params': params, 'batch_stats': state.batch_stats}\n        new_variables, recon_x, latent_vec = models.model(latent_dim, fmri_voxels).apply(\n            variables, \n            batch, \n            training=True,\n            mutable=['batch_stats']\n        )\n        mse_loss = jnp.mean(jnp.square(recon_x - batch))\n        return mse_loss, new_variables['batch_stats']\n\n    (loss, new_batch_stats), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n    state = state.apply_gradients(grads=grads)\n    state = state.replace(batch_stats=new_batch_stats)\n    return state, loss\n```\n\n2. Modify the `evaluate_fun` function:\n\n```python\ndef evaluate_fun(state, loader, key, latent_dim, num_steps=2):\n    def eval_model(batch):\n        variables = {'params': state.params, 'batch_stats': state.batch_stats}\n        reconstruction, latent_vecs = models.model(latent_dim, batch.shape[1]).apply(\n            variables, \n            batch,\n            training=False,\n            mutable=False\n        )\n        metrics = compute_metrics(reconstruction, batch)\n        return metrics, (batch, reconstruction), latent_vecs\n\n    evaluations = []\n    for _ in range(num_steps):\n        batch = next(loader)\n        eval = eval_model(batch)\n        evaluations.append(eval)\n    return evaluations\n```\n\n3. Update the TrainState initialization to include batch_stats:\n\n```python\nclass TrainState(train_state.TrainState):\n    batch_stats: dict\n\n# In train_and_evaluate:\nvariables = models.model(config.latent_dim, fmri_voxels).init(\n    rng, init_data, training=True\n)\nstate = TrainState.create(\n    apply_fn=models.model(config.latent_dim, fmri_voxels).apply,\n    params=variables['params'],\n    tx=optax.adamw(config.learning_rate),\n    batch_stats=variables['batch_stats']\n)\n```\n\n4. Update the model evaluation calls to pass the full state instead of just params:\n\n```python\n# Instead of passing state.params, pass the full state\nevaluations = evaluate_fun(\n    state, train_loader, key, config.latent_dim, num_steps=5\n)\n\n# Similarly for test evaluation\nevaluations = evaluate_fun(\n    state, test_loader, key, config.latent_dim, num_steps=test_size // config.batch_size\n)\n```\n\nThese changes ensure that:\n- Batch statistics are properly tracked during training\n- The statistics are used during evaluation\n- The mutable collections are properly handled throughout the training process\n\nMake sure your model definition in `models.py` also properly uses BatchNorm with the correct configuration. The BatchNorm layers should be initialized with `use_running_average=False` during training and `use_running_average=True` during inference.\n","messages":[{"id":{"replica_id":0,"value":0},"start":0,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":403}}},{"id":{"replica_id":0,"value":370},"start":8122,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":404}}},{"id":{"replica_id":0,"value":371},"start":11387,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":405}}}],"summary":"Autoencoder Training Flow Analysis Feedback","slash_command_output_sections":[]}